{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>KOLHE_PRANAV_HW3</h1></center>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Pranav Kolhe\n",
    "<br>\n",
    "Github Username: pranavko12\n",
    "<br>\n",
    "USC ID: 6981095982"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Time Series Classification Part 1: Feature Creation/Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Download Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Package imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the AReM Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute path: C:\\Users\\admin\\Desktop\\MS\\Sem 3\\DSML\\Homework\\data\\AReM\n",
      "Does this path exist? False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "data_path = \"../data/AReM/\"\n",
    "absolute_path = os.path.abspath(data_path)\n",
    "print(f\"Absolute path: {absolute_path}\")\n",
    "\n",
    "print(\"Does this path exist?\", os.path.exists(absolute_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DATA CLEANING**<br>\n",
    "The above code cleans 3 datasets.<br>\n",
    "1. dataset4 in bending2 folder has a space delimeter instead of comma.\n",
    "2. dataset9 and dataset14 from cycling folder have additional comma. Hence, row 485 has 8 values instead of 7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Test and Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing bending1: 0 files found\n",
      "bending1: 0 test datasets, 0 train datasets\n",
      "\n",
      "Processing bending2: 0 files found\n",
      "bending2: 0 test datasets, 0 train datasets\n",
      "\n",
      "Processing cycling: 0 files found\n",
      "cycling: 0 test datasets, 0 train datasets\n",
      "\n",
      "Processing lying: 0 files found\n",
      "lying: 0 test datasets, 0 train datasets\n",
      "\n",
      "Processing sitting: 0 files found\n",
      "sitting: 0 test datasets, 0 train datasets\n",
      "\n",
      "Processing standing: 0 files found\n",
      "standing: 0 test datasets, 0 train datasets\n",
      "\n",
      "Processing walking: 0 files found\n",
      "walking: 0 test datasets, 0 train datasets\n",
      "\n",
      "Final Training set shape: (0, 0)\n",
      "Final Testing set shape: (0, 0)\n"
     ]
    }
   ],
   "source": [
    "for folder, data_list in arem_data.items():\n",
    "    test_data = []\n",
    "    train_data = []\n",
    "\n",
    "    file_list = glob.glob(data_folders[folder])\n",
    "    print(f\"\\nProcessing {folder}: {len(file_list)} files found\")\n",
    "\n",
    "    for i, df in enumerate(data_list):\n",
    "        file_name = file_list[i] if i < len(file_list) else \"Unknown\"\n",
    "\n",
    "        if df is None or df.empty:\n",
    "            print(f\"Skipping empty dataset: {file_name}\")\n",
    "            continue\n",
    "\n",
    "        if folder in [\"bending1\", \"bending2\"]:\n",
    "            if \"dataset1.csv\" in file_name or \"dataset2.csv\" in file_name:\n",
    "                test_data.append(df)\n",
    "            else:\n",
    "                train_data.append(df)\n",
    "        else:\n",
    "            if \"dataset1.csv\" in file_name or \"dataset2.csv\" in file_name or \"dataset3.csv\" in file_name:\n",
    "                test_data.append(df)\n",
    "            else:\n",
    "                train_data.append(df)\n",
    "\n",
    "    print(f\"{folder}: {len(test_data)} test datasets, {len(train_data)} train datasets\")\n",
    "\n",
    "    folder_test.extend(test_data)\n",
    "    folder_train.extend(train_data)\n",
    "\n",
    "if folder_test:\n",
    "    arem_test = pd.concat(folder_test, ignore_index=True).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "else:\n",
    "    arem_test = pd.DataFrame()\n",
    "\n",
    "if folder_train:\n",
    "    arem_train = pd.concat(folder_train, ignore_index=True).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "else:\n",
    "    arem_train = pd.DataFrame()\n",
    "\n",
    "print(f\"\\nFinal Training set shape: {arem_train.shape}\")\n",
    "print(f\"Final Testing set shape: {arem_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "arem_test = pd.concat(folder_test, ignore_index=True).sample(frac=1, random_state=42).reset_index(drop=True) if folder_test else pd.DataFrame()\n",
    "arem_train = pd.concat(folder_train, ignore_index=True).sample(frac=1, random_state=42).reset_index(drop=True) if folder_train else pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing set shape: (0, 0)\n",
      "Training set shape: (0, 0)\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing set shape:\", arem_test.shape)\n",
    "print(\"Training set shape:\", arem_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### i. Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### ii. Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### iii. Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### iv. Select Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ISLR 3.7.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Linear Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Linear Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Not Linear Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Not Linear Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ISLR 3.7.3 - Extra Practice "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ISLR 3.7.5 - Extra Practice "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**REFERENCES**<br>\n",
    "1. Chatgpt Prompt: \"how do i get all files from the folder at once?\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "294.435px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "3c20c2d94d2527936fe0f3a300eb11db30fed84423423838e2f93b74eb7aaebc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
